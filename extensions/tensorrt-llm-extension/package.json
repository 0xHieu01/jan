{
  "name": "@janhq/tensorrt-llm-extension",
  "productName": "TensorRT-LLM Inference Engine",
  "version": "0.0.3",
  "description": "This extension enables Nvidia's TensorRT-LLM for the fastest GPU acceleration. See the [setup guide](https://jan.ai/guides/providers/tensorrt-llm/) for next steps.",
  "main": "dist/index.js",
  "node": "dist/node/index.cjs.js",
  "author": "Jan <service@jan.ai>",
  "license": "AGPL-3.0",
  "config": {
    "host": "127.0.0.1",
    "port": "3929"
  },
  "compatibility": {
    "platform": [
      "win32"
    ],
    "app": [
      "0.1.0"
    ]
  },
  "tensorrtVersion": "0.1.8",
  "provider": "nitro-tensorrt-llm",
  "scripts": {
    "test": "jest",
    "build": "rolldown -c rolldown.config.mjs",
    "build:publish": "rimraf *.tgz --glob || true && yarn build && cpx \"bin/**\" \"dist/bin\" && npm pack && cpx *.tgz ../../pre-install"
  },
  "exports": {
    ".": "./dist/index.js",
    "./main": "./dist/node/index.cjs.js"
  },
  "devDependencies": {
    "@types/decompress": "4.2.7",
    "@types/jest": "^29.5.12",
    "@types/node": "^20.11.4",
    "@types/os-utils": "^0.0.4",
    "@types/tcp-port-used": "^1.0.4",
    "cpx": "^1.5.0",
    "download-cli": "^1.1.1",
    "jest": "^29.7.0",
    "jest-junit": "^16.0.0",
    "jest-runner": "^29.7.0",
    "rimraf": "^3.0.2",
    "rolldown": "1.0.0-beta.1",
    "run-script-os": "^1.1.6",
    "ts-jest": "^29.2.5",
    "typescript": "^5.2.2"
  },
  "dependencies": {
    "@janhq/core": "../../core/package.tgz",
    "decompress": "^4.2.1",
    "fetch-retry": "^5.0.6",
    "rxjs": "^7.8.1",
    "tcp-port-used": "^1.0.2",
    "terminate": "^2.6.1",
    "ulidx": "^2.3.0"
  },
  "engines": {
    "node": ">=18.0.0"
  },
  "files": [
    "dist/*",
    "package.json",
    "README.md"
  ],
  "bundleDependencies": [
    "tcp-port-used",
    "fetch-retry",
    "decompress",
    "@janhq/core",
    "terminate"
  ],
  "installConfig": {
    "hoistingLimits": "workspaces"
  },
  "packageManager": "yarn@4.5.3"
}
